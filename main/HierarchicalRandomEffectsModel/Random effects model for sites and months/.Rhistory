library(ggplot2)
library(POT)
library(lubridate)
library(evir)
library(coda)
library(nimble)
Ireland <- read.csv('.../GitHub/Bayesian-Approach-to-EVT/Dataset/Ireland_daily_from1990.csv')
head(Ireland)
unique(Ireland$spot)
df <- data.frame(time=Ireland$year, obs=Ireland$hg, county=Ireland$spot)
n <- length(df$obs)
m <- length(unique(df$county))
spots <- list()
data <- list()
counties <- as.vector(unique(Ireland$spot))
for(i in 1:m){
county <- Ireland[which(Ireland$spot==counties[i]),]
spots[[i]] <- data.frame(time=county$year, obs=county$hg) # Raccolgo in una lista le osservazioni divise per siti
data[[i]] <- county$hg
plot(pacf(spots[[i]]$obs))
readline(prompt = "press [enter] to continue or ESC to stop")
graphics.off()
}
thresholds <- c(95,95,94,94,85)
lambda <- rep(NA,m)
for(i in 1:m){
lambda[i] <- length(spots[[i]][which(spots[[i]]$obs>thresholds[i]),2])/length(spots[[i]]$obs)
}
N<-length(data[[1]])
datamatrix<-matrix(NA,N,m)
for(i in 1:N){
for(j in 1:m){
datamatrix[i,j]<-spots[[j]][i,2]
}
}
FOMC_logit_GPD_joint_density <- nimbleFunction(
run = function(x1=double(0),x2=double(0),threshold=double(0),sigma=double(0),xi=double(0),alpha=double(0), lambda=double(0)){
returnType(double(0))
if(x1>threshold & x2>threshold){
return(-((1 + xi*(-threshold + x1)/sigma)^(1/xi)/lambda)^(-1/alpha)*((1 + xi*(-threshold + x2)/sigma)^(1/xi)/lambda)^(-1/alpha)*(((1 + xi*(-threshold + x2)/sigma)^(1/xi)/lambda)^(-1/alpha) + ((1 + xi*(-threshold + x1)/sigma)^(1/xi)/lambda)^(-1/alpha))^alpha/(sigma^2*(1 + xi*(-threshold + x1)/sigma)*(1 + xi*(-threshold + x2)/sigma)*(((1 + xi*(-threshold + x2)/sigma)^(1/xi)/lambda)^(-1/alpha) + ((1 + xi*(-threshold + x1)/sigma)^(1/xi)/lambda)^(-1/alpha))^2) + ((1 + xi*(-threshold + x1)/sigma)^(1/xi)/lambda)^(-1/alpha)*((1 + xi*(-threshold + x2)/sigma)^(1/xi)/lambda)^(-1/alpha)*(((1 + xi*(-threshold + x2)/sigma)^(1/xi)/lambda)^(-1/alpha) + ((1 + xi*(-threshold + x1)/sigma)^(1/xi)/lambda)^(-1/alpha))^alpha/(alpha*sigma^2*(1 + xi*(-threshold + x1)/sigma)*(1 + xi*(-threshold + x2)/sigma)*(((1 + xi*(-threshold + x2)/sigma)^(1/xi)/lambda)^(-1/alpha) + ((1 + xi*(-threshold + x1)/sigma)^(1/xi)/lambda)^(-1/alpha))^2));
}
if(x1>threshold & x2<=threshold){
return(((1 + xi*(-threshold + x1)/sigma)^(1/xi)/lambda)^(-1/alpha)*((1/lambda)^(-1/alpha) + ((1 + xi*(-threshold + x1)/sigma)^(1/xi)/lambda)^(-1/alpha))^alpha/(sigma*(1 + xi*(-threshold + x1)/sigma)*((1/lambda)^(-1/alpha) + ((1 + xi*(-threshold + x1)/sigma)^(1/xi)/lambda)^(-1/alpha))));
}
if(x1<=threshold & x2>threshold){
return(((1 + xi*(-threshold + x2)/sigma)^(1/xi)/lambda)^(-1/alpha)*((1 /lambda)^(-1/alpha) + ((1 + xi*(-threshold + x2)/sigma)^(1/xi)/lambda)^(-1/alpha))^alpha/(sigma*(1 + xi*(-threshold + x2)/sigma)*((1/lambda)^(-1/alpha) + ((1 + xi*(-threshold + x2)/sigma)^(1/xi)/lambda)^(-1/alpha))));
}
else{
return(1-(((1/lambda)^(-1/alpha) + (1/lambda)^(-1/alpha))^(alpha)));
}
})
GPD_density <- nimbleFunction(
run=function(x=double(0),threshold=double(0),scale=double(0), xi=double(0), lambda=double(0)){
returnType(double(0))
if(x >= threshold){
if(abs(xi) <= 1e-15)
{return( lambda/scale*exp(-(x-threshold)/scale))}
else
{return((lambda/scale) * (1 + (xi * (x - threshold))/scale)^((-1/xi) - 1))}
}
else{
return((1-lambda)/threshold)
}
})
dmyModel_lpost <- nimbleFunction(
run=function(x=double(1),threshold=double(0),scale=double(0),xi=double(0), lambda=double(0), alpha=double(0),log = integer(0, default = 0)){
returnType(double(0))
loglikelihood <- log(GPD_density(x[1], threshold,scale,xi,lambda))
num <-0
denom <-0
for(i in 1:(length(x)-1)){
num <- log(FOMC_logit_GPD_joint_density(x[i],x[i+1],  threshold,scale,xi, alpha, lambda)) +num
denom <- log(GPD_density(x[i],  threshold,scale,xi, lambda)) + denom
}
loglikelihood <- loglikelihood + num - denom
if(log) return(loglikelihood)
else return(exp(loglikelihood))
}
)
code <- nimbleCode({
for(i in 1:M){
y[1:N,i] ~ dmyModel_lpost(threshold[i],sigma[i],xi[i],lambda[i],alpha[i])}
for(i in 1:M){
constraint_data[i] ~ dconstraint( xi[i] > -sigma[i]/(max(y[1:N,i])-threshold[i]))
xi[i] ~ dnorm(a_xi,phi_xi)
sigma[i] <- exp(logsigma[i])
logsigma[i] ~ dnorm(a_sigma,phi_sigma)
alpha[i] ~ dunif(0,1)}
a_sigma ~ dnorm(b,c)
a_xi ~ dnorm(b,c)
#  phi_sigma ~ dgamma(f,f)
#  phi_xi ~ dgamma(f,f)
phi_sigma ~ dunif(d,e)
phi_xi ~ dunif(f,g)
})
pumpConsts <- list(M= m, N=N,threshold = thresholds, lambda = lambda, b=0, c=10^-2,d=5*10^-3,e=15*10^-3,f=5*10^-2,g=15*10^-2)
pumpData <-list(y = datamatrix)
Ireland <- read.csv('.../GitHub/Bayesian-Approach-to-EVT/Dataset/Ireland_daily_from1990.csv')
Ireland <- read.csv('...Dataset/Ireland_daily_from1990.csv')
Ireland <- read.csv('C:/Users/matte/OneDrive/Documenti/GitHub/Bayesian-Approach-to-EVT/Dataset/Ireland_daily_from1990.csv')
head(Ireland)
unique(Ireland$spot)
df <- data.frame(time=Ireland$year, obs=Ireland$hg, county=Ireland$spot)
n <- length(df$obs)
m <- length(unique(df$county))
spots <- list()
data <- list()
counties <- as.vector(unique(Ireland$spot))
for(i in 1:m){
county <- Ireland[which(Ireland$spot==counties[i]),]
spots[[i]] <- data.frame(time=county$year, obs=county$hg) # Raccolgo in una lista le osservazioni divise per siti
data[[i]] <- county$hg
plot(pacf(spots[[i]]$obs))
readline(prompt = "press [enter] to continue or ESC to stop")
graphics.off()
}
thresholds <- c(95,95,94,94,85)
lambda <- rep(NA,m)
for(i in 1:m){
lambda[i] <- length(spots[[i]][which(spots[[i]]$obs>thresholds[i]),2])/length(spots[[i]]$obs)
}
N<-length(data[[1]])
datamatrix<-matrix(NA,N,m)
for(i in 1:N){
for(j in 1:m){
datamatrix[i,j]<-spots[[j]][i,2]
}
}
FOMC_logit_GPD_joint_density <- nimbleFunction(
run = function(x1=double(0),x2=double(0),threshold=double(0),sigma=double(0),xi=double(0),alpha=double(0), lambda=double(0)){
returnType(double(0))
if(x1>threshold & x2>threshold){
return(-((1 + xi*(-threshold + x1)/sigma)^(1/xi)/lambda)^(-1/alpha)*((1 + xi*(-threshold + x2)/sigma)^(1/xi)/lambda)^(-1/alpha)*(((1 + xi*(-threshold + x2)/sigma)^(1/xi)/lambda)^(-1/alpha) + ((1 + xi*(-threshold + x1)/sigma)^(1/xi)/lambda)^(-1/alpha))^alpha/(sigma^2*(1 + xi*(-threshold + x1)/sigma)*(1 + xi*(-threshold + x2)/sigma)*(((1 + xi*(-threshold + x2)/sigma)^(1/xi)/lambda)^(-1/alpha) + ((1 + xi*(-threshold + x1)/sigma)^(1/xi)/lambda)^(-1/alpha))^2) + ((1 + xi*(-threshold + x1)/sigma)^(1/xi)/lambda)^(-1/alpha)*((1 + xi*(-threshold + x2)/sigma)^(1/xi)/lambda)^(-1/alpha)*(((1 + xi*(-threshold + x2)/sigma)^(1/xi)/lambda)^(-1/alpha) + ((1 + xi*(-threshold + x1)/sigma)^(1/xi)/lambda)^(-1/alpha))^alpha/(alpha*sigma^2*(1 + xi*(-threshold + x1)/sigma)*(1 + xi*(-threshold + x2)/sigma)*(((1 + xi*(-threshold + x2)/sigma)^(1/xi)/lambda)^(-1/alpha) + ((1 + xi*(-threshold + x1)/sigma)^(1/xi)/lambda)^(-1/alpha))^2));
}
if(x1>threshold & x2<=threshold){
return(((1 + xi*(-threshold + x1)/sigma)^(1/xi)/lambda)^(-1/alpha)*((1/lambda)^(-1/alpha) + ((1 + xi*(-threshold + x1)/sigma)^(1/xi)/lambda)^(-1/alpha))^alpha/(sigma*(1 + xi*(-threshold + x1)/sigma)*((1/lambda)^(-1/alpha) + ((1 + xi*(-threshold + x1)/sigma)^(1/xi)/lambda)^(-1/alpha))));
}
if(x1<=threshold & x2>threshold){
return(((1 + xi*(-threshold + x2)/sigma)^(1/xi)/lambda)^(-1/alpha)*((1 /lambda)^(-1/alpha) + ((1 + xi*(-threshold + x2)/sigma)^(1/xi)/lambda)^(-1/alpha))^alpha/(sigma*(1 + xi*(-threshold + x2)/sigma)*((1/lambda)^(-1/alpha) + ((1 + xi*(-threshold + x2)/sigma)^(1/xi)/lambda)^(-1/alpha))));
}
else{
return(1-(((1/lambda)^(-1/alpha) + (1/lambda)^(-1/alpha))^(alpha)));
}
})
GPD_density <- nimbleFunction(
run=function(x=double(0),threshold=double(0),scale=double(0), xi=double(0), lambda=double(0)){
returnType(double(0))
if(x >= threshold){
if(abs(xi) <= 1e-15)
{return( lambda/scale*exp(-(x-threshold)/scale))}
else
{return((lambda/scale) * (1 + (xi * (x - threshold))/scale)^((-1/xi) - 1))}
}
else{
return((1-lambda)/threshold)
}
})
dmyModel_lpost <- nimbleFunction(
run=function(x=double(1),threshold=double(0),scale=double(0),xi=double(0), lambda=double(0), alpha=double(0),log = integer(0, default = 0)){
returnType(double(0))
loglikelihood <- log(GPD_density(x[1], threshold,scale,xi,lambda))
num <-0
denom <-0
for(i in 1:(length(x)-1)){
num <- log(FOMC_logit_GPD_joint_density(x[i],x[i+1],  threshold,scale,xi, alpha, lambda)) +num
denom <- log(GPD_density(x[i],  threshold,scale,xi, lambda)) + denom
}
loglikelihood <- loglikelihood + num - denom
if(log) return(loglikelihood)
else return(exp(loglikelihood))
}
)
code <- nimbleCode({
for(i in 1:M){
y[1:N,i] ~ dmyModel_lpost(threshold[i],sigma[i],xi[i],lambda[i],alpha[i])}
for(i in 1:M){
constraint_data[i] ~ dconstraint( xi[i] > -sigma[i]/(max(y[1:N,i])-threshold[i]))
xi[i] ~ dnorm(a_xi,phi_xi)
sigma[i] <- exp(logsigma[i])
logsigma[i] ~ dnorm(a_sigma,phi_sigma)
alpha[i] ~ dunif(0,1)}
a_sigma ~ dnorm(b,c)
a_xi ~ dnorm(b,c)
#  phi_sigma ~ dgamma(f,f)
#  phi_xi ~ dgamma(f,f)
phi_sigma ~ dunif(d,e)
phi_xi ~ dunif(f,g)
})
pumpConsts <- list(M= m, N=N,threshold = thresholds, lambda = lambda, b=0, c=10^-2,d=5*10^-3,e=15*10^-3,f=5*10^-2,g=15*10^-2)
pumpData <-list(y = datamatrix)
pumpInits <- list()
Hmodel <- nimbleModel(code=code, name ="Hmodel", constants = pumpConsts, data=pumpData, inits = pumpInits)
configureMCMC(Hmodel)
mcmc.out <- nimbleMCMC(model = Hmodel,
niter = 8000, nchains = 3, thin = 10, nburnin = 2000,
monitors = c("a_sigma","a_xi","phi_sigma","phi_xi", "logsigma", "xi", "alpha", "sigma"),
summary = TRUE, WAIC = TRUE, samplesAsCodaMCMC  = TRUE, setSeed = TRUE)
coda_chain<- mcmc.out$samples
summary(coda_chain)
gelman.diag(coda_chain, confidence = 0.95,  autoburnin = TRUE, multivariate=TRUE)
x11()
plot(coda_chain)
acfplot(coda_chain)
cumuplot(coda_chain)
geweke.diag(coda_chain)
sigmacb<-coda_chain$chain2[,"sigma[4]"]
sigmacb<-coda_chain$chain2[,"sigma[4]"]
xicb <- coda_chain$chain2[,"xi[4]"]
obs <- datamatrix[,4]
threshold<-thresholds[4]
estim = cbind( sigmacb, xicb)
ests <- c(mean(estim[, 1]), mean(estim[, 2]))
ests1 <- c(median(estim[, 1]), median(estim[, 2]))
ests2 <- array(0, c(2, 2))
ests2[1, ] <- c(quantile(estim[, 1], 0.025), quantile(estim[, 2], 0.025))
ests2[2, ] <- c(quantile(estim[, 1], 0.975), quantile(estim[, 2], 0.975))
results <- list(posterior = estim, data = obs, postmean = ests,
postmedian = ests1, postCI = ests2, block = 100)
names(results$postmean) <- c("sigma", "xi")
names(results$postmedian) <- c( "sigma", "xi")
dimnames(results$postCI) <- list(c("lower bound", "upper bound"),
c( "sigma", "xi"))
class(results) <- "gpdp"
k <- 100   #end ret level
t <- 2  #start ret level
x <- results
sampl <- qgpd(1 - 1/t, x$posterior[, 2], thresholds[1], x$posterior[, 1])
res <- quantile(sampl, 0.5)
ta <- seq(1, k, 1)
n <- length(ta)
li <- array(0, c(n))
ls <- array(0, c(n))
pred <- array(0, c(n))
for (s in 1:n) {
sampl <- qgpd(1 - 1/s, x$posterior[, 2], thresholds[1], x$posterior[, 1])
li[s] <- quantile(sampl, 0.025)
ls[s] <- quantile(sampl, 0.975)
pred[s] <- quantile(sampl, 0.5)
}
x11()
x11()
ggplot(data = data.frame( level= ta, intensity=pred), mapping = aes(x=level,y=intensity)) +
geom_line( color = "red") +
xlab("level") +
ylab("wind speed (kmh)") +
ggtitle("Return level") +
xlim(0,100)+
ylim(80,160) +
geom_line(aes(y = li), color = "black", linetype = "dotted") +
geom_line(aes(y = ls), color = "black", linetype = "dotted")
x11()
ggplot(data = data.frame( level= ta, intensity=pred), mapping = aes(x=level,y=intensity)) +
geom_line( color = "red") +
xlab("level") +
ylab("wind speed (kmh)") +
ggtitle("Return level") +
xlim(0,100)+
ylim(80,200) +
geom_line(aes(y = li), color = "black", linetype = "dotted") +
geom_line(aes(y = ls), color = "black", linetype = "dotted")
graphics.off()
data <- x$data[x$data > threshold]
linf = min(data)
lsup = max(data)
dat1 = seq(linf, lsup, (lsup - linf)/300)
n = length(dat1)
int = length(x$posterior[, 1])
res = array(0, c(n))
for (i in 1:n) {
for (j in 1:int) {
res[i] = res[i] + (1/int) * dgpd(dat1[i], x$posterior[j, 2], threshold, x$posterior[j, 1])
}
}
dataf <- data.frame(log_pos = data)
dataf2 <- data.frame(data = dat1, res = res)
ggplot(dataf, aes(x=log_pos)) +
geom_histogram(aes(y = ..density.. ), bins = 20, color = "black", fill = "lightblue") +
xlab("data") +
ylab("density") +
ggtitle("density") +
geom_line(aes(x=data,y = res), dataf2,color = "red")
library(rstan)
library(coda)
library(tidyverse)
library(POT)
library(evir)
library(loo)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
Ireland <- read.csv('C:/Users/matte/OneDrive/Documenti/GitHub/Bayesian-Approach-to-EVT/Dataset/Ireland_daily_from1990.csv')
head(Ireland)
unique(Ireland$spot)
Ireland<-separate(Ireland,"date", c("day","month","y"),sep = "-")
unique(Ireland$month)
S <- length(unique(Ireland$spot))
M <- length(unique(Ireland$month))
Ireland_monthly <- list()
counties <- as.vector(unique(Ireland$spot))
months <- as.vector(unique(Ireland$month))
r <- rep(NA,M)
for(i in 1:M){
monthly <- Ireland[which(Ireland$month==months[i]),]
Ireland_monthly[[i]] <- data.frame(time=monthly$year, obs=monthly$hg, county = monthly$spot)
r[i] <- length(Ireland_monthly[[i]]$obs)
}
for(i in 1:M){
data<-matrix(NA,(r[i]/5),S)
for(j in 1:S){
county<-Ireland_monthly[[i]][which(Ireland_monthly[[i]]$county==counties[j]),]
for(n in 1:(r[i]/5)){
data[n,j]<-county$obs[n]
}
}
Ireland_monthly[[i]]<-data
}
thresholds <- rbind(c(70,   80,   75,   80,   61),
c(78,   70,   80,   80,   60),
c(79,   72,   75,   76,   56),
c(63,   70,   70,   72,   61),
c(70,   63,   65,   68,   60),
c(62,   60,   60,   64,   58),
c(55,   58,   63,   58,   50),
c(58,   56,   55,   55,   40),
c(56,   57,   60,   56,   45),
c(63,   70,   65,   78,   60),
c(68,   70,   68,   69,   57),
c(75,   70,   70,   84,   64))
lambda <- matrix(NA,M,S)
for(i in 1:M){
for(j in 1:S){
lambda[i,j] <- length(Ireland_monthly[[i]][which(Ireland_monthly[[i]][,j]>thresholds[i,j]),j])/r[i]
}
}
maxim <- matrix(NA,M,S)
for(i in 1:M){
for(j in 1:S){
maxim[i,j] <- max(Ireland_monthly[[i]][,j])
}
}
data_win <- list( S = S, M = M, r = r/5,
y_dec = Ireland_monthly[[1]], y_jan = Ireland_monthly[[2]], y_feb = Ireland_monthly[[3]],
y_mar = Ireland_monthly[[4]], y_apr = Ireland_monthly[[5]], y_may = Ireland_monthly[[6]],
y_jun = Ireland_monthly[[7]], y_jul = Ireland_monthly[[8]], y_aug = Ireland_monthly[[9]],
y_sep = Ireland_monthly[[10]], y_oct = Ireland_monthly[[11]], y_nov = Ireland_monthly[[12]],
threshold = thresholds, lambda = lambda,maxim=maxim)
fit <- stan(file = "Hierarchical_model_Full.stan", data = data_win, warmup = 800, iter = 1000,
chains = 2, thin = 1,seed = 19, init_r= 0.01)
setwd("C:/Users/matte/OneDrive/Documenti/GitHub/Bayesian-Approach-to-EVT/main/HierarchicalRandomEffectsModel/Random effects model for sites and months")
fit <- stan(file = "Hierarchical_model_Full.stan", data = data_win, warmup = 800, iter = 1000,
chains = 2, thin = 1,seed = 19, init_r= 0.01)
print(fit, par = c('a_sigma','phi_sigma','a_xi','phi_xi','sigma', 'xi','alpha'))
#PLOT dell 3 catene generate per ogni parametro
rstan::traceplot(fit, pars='a_sigma', inc_warmup = TRUE)
rstan::traceplot(fit, pars='phi_sigma', inc_warmup = TRUE)
rstan::traceplot(fit, pars='a_xi', inc_warmup = TRUE)
rstan::traceplot(fit, pars='phi_xi', inc_warmup = TRUE)
rstan::traceplot(fit, pars='sigma', inc_warmup = TRUE)
rstan::traceplot(fit, pars='xi', inc_warmup = TRUE)
rstan::traceplot(fit, pars='alpha', inc_warmup = TRUE)
par <- rstan::extract(fit, pars = c('a_sigma','phi_sigma', 'a_xi','phi_xi',"sigma", "xi","alpha", "lp__"), inc_warmup = FALSE)
names(par)
sigmacb <- par$sigma
sigmacb
xicb <- par$xi
alphacb <- par$alpha
plot(sigmacb)
plot(xicb)
plot(alphacb)
coda_chain <- As.mcmc.list(fit, pars = c('a_sigma','phi_sigma','a_xi','phi_xi',"sigma", "xi", 'alpha'))
summary(coda_chain)
gelman.diag(coda_chain, confidence = 0.95,  autoburnin = TRUE, multivariate=TRUE)
x11()
plot(coda_chain)
x11()
plot(coda_chain)
acfplot(coda_chain)
geweke.diag(coda_chain)
sigmacb=sigmacb[,8]
sigmacb=sigmacb[4][,2]
sigmacb=sigmacb[[4]][,2]
## Change the first four lines to analyze different sites in different month,
## in example, we are considering i = 2, which is january and j=4 which is Kerry
is(sigmacb)
dim(sigmacb)
sigmacb=sigmacb[,2,4]
xicb=xicb[,2,4]
threshold=thresholds[2,4]
obs <- Ireland_monthly[[2]][,4]
estim = cbind( sigmacb, xicb)
ests <- c(mean(estim[, 1]), mean(estim[, 2]))
ests1 <- c(median(estim[, 1]), median(estim[, 2]))
ests2 <- array(0, c(2, 2))
ests2[1, ] <- c(quantile(estim[, 1], 0.025), quantile(estim[, 2], 0.025))
ests2[2, ] <- c(quantile(estim[, 1], 0.975), quantile(estim[, 2], 0.975))
results <- list(posterior = estim, data = obs, postmean = ests,
postmedian = ests1, postCI = ests2, block = 100)
names(results$postmean) <- c("sigma", "xi")
names(results$postmedian) <- c( "sigma", "xi")
dimnames(results$postCI) <- list(c("lower bound", "upper bound"),
c( "sigma", "xi"))
class(results) <- "gpdp"
t <- 2  #start ret level
k <- 100   #end ret level
x <- results
sampl <- qgpd(1 - 1/t, x$posterior[, 2], thresholds[1], x$posterior[, 1])
res <- quantile(sampl, 0.5)
ta <- seq(1, k, 1)
n <- length(ta)
li <- array(0, c(n))
ls <- array(0, c(n))
pred <- array(0, c(n))
for (s in 1:n) {
sampl <- qgpd(1 - 1/s, x$posterior[, 2], thresholds[1], x$posterior[, 1])
li[s] <- quantile(sampl, 0.025)
ls[s] <- quantile(sampl, 0.975)
pred[s] <- quantile(sampl, 0.5)
}
x11()
ggplot(data = data.frame( level= ta, intensity=pred), mapping = aes(x=level,y=intensity)) +
geom_line( color = "red") +
xlab("level") +
ylab("wind speed (kmh)") +
ggtitle("Return level") +
xlim(0,100)+
ylim(80,160) +
geom_line(aes(y = li), color = "black", linetype = "dotted") +
geom_line(aes(y = ls), color = "black", linetype = "dotted")
graphics.off()
data <- x$data[x$data > threshold]
linf = min(data)
lsup = max(data)
dat1 = seq(linf, lsup, (lsup - linf)/300)
n = length(dat1)
int = length(x$posterior[, 1])
res = array(0, c(n))
for (i in 1:n) {
for (j in 1:int) {
res[i] = res[i] + (1/int) * dgpd(dat1[i], x$posterior[j, 2], threshold, x$posterior[j, 1])
}
}
dataf <- data.frame(log_pos = data)
dataf2 <- data.frame(data = dat1, res = res)
ggplot(dataf, aes(x=log_pos)) +
geom_histogram(aes(y = ..density.. ), bins = 20, color = "black", fill = "lightblue") +
xlab("data") +
ylab("density") +
ggtitle("density") +
geom_line(aes(x=data,y = res), dataf2,color = "red")
